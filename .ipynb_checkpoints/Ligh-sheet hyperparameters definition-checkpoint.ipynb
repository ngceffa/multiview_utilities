{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ec832d",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701cb9e",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from scipy.optimize import curve_fit\n",
    "# local folder with homemade libraries\n",
    "sys.path.append('/home/ngc/Documents/GitHub/multiview_utilities')\n",
    "# HOMEMADE LIBRARIES AND IMPORTS\n",
    "import math_utils as matut\n",
    "import raw_images_manipulation_utilities as rim\n",
    "importlib.reload(matut);\n",
    "importlib.reload(rim); # reload the modules for updating to eventual changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc2e53",
   "metadata": {},
   "source": [
    "#### Local variables and constants.\n",
    "\n",
    "Carefully read and change the variables in the next sectionto match the volume to be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d58c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICES = 53 # number of images for each volume\n",
    "TIMEPOINTS =  161 # number of acquired volumes\n",
    "TOTAL_IMAGES = TIMEPOINTS * SLICES # total of raw data-images\n",
    "IMAGES_DIMENSION = 1024 # assumed square images.\n",
    "# N.b. try to have 2^n pixels: it speeds up FFt calculations.\n",
    "# Folder to get data and save data:\n",
    "RAW_SLICES_FOLDER = '/home/ngc/Data/560_other_larva'\n",
    "BACKGROUND_FOLDER = '/home/ngc/Data/16_06/fift_1_percent_agar_20210616_164944'\n",
    "VOLUMES_OUTPUT_FOLDER = '/home/ngc/Data/560_other_larva/output_test'\n",
    "PARAMS_OUTPUT_FOLDER = '/home/ngc/Data/560_other_larva'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ce830",
   "metadata": {},
   "source": [
    "Create a list of names of all the volumes as \n",
    "**[timepoint (int), vol_cam_0 [str], vol_cam_1 (str)]**\n",
    "next function uses a default file names paradigm, \n",
    "as saved by Labview software\n",
    "(check arguments in \"raw_images_manipulation_utilities\" library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = rim.file_names_list(TIMEPOINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d08d3",
   "metadata": {},
   "source": [
    "#### Camera offset compensation\n",
    "\n",
    "The cameras are not pixel-exactly aligned: the offset in their views\n",
    "can be calculated with a 2D cross-correlation.\n",
    "This process returns a 2D displacement vector, \n",
    "that will be addedd (during image processing) to CAM_01 \n",
    "to have a better superpositoin with CAM_00.\n",
    "(the opposite is also fine, subtracting from CAM_00)\n",
    "In the next cell:\n",
    "\n",
    "1. Select a volume, and in that volume a (few) slice(s) that will be used to find the 2D mismatch.\n",
    "\n",
    "2. A pictorial result will tell if it worked. It should consist of: two superimposed imaged before displacement, after displacement, and a print() of the displacement vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint_for_offset_calculation = 0 # it should not have any impact\n",
    "\n",
    "# select some slices to be used in the offset calculation.\\\n",
    "# Usually some central slices with a nice amount of information will do.\n",
    "slices_for_offset_calculation = np.asarray((10, 15, 22, 30, 35)) \n",
    "# Instead of using all the image (it can be absolutely done) \n",
    "# go quicker and use only a square central region of \"extent\" side\n",
    "extent = 800\n",
    "\n",
    "centre = IMAGES_DIMENSION / 2\n",
    "shift_row, shift_col = 0, 0\n",
    "\n",
    "# Open the stacks\n",
    "stack_0 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint_for_offset_calculation][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "stack_1 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint_for_offset_calculation][2],\n",
    "    BACKGROUND_FOLDER + '/Background_1.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "\n",
    "for i in slices_for_offset_calculation:\n",
    "    image_0 = stack_0[i, :, :]\n",
    "    image_1 = stack_1[i, :, :]\n",
    "    image_0_b = image_0[int(centre - extent/2):int(centre + extent/2),\n",
    "                        int(centre - extent/2):int(centre + extent/2)]\n",
    "    image_1_b = image_1[int(centre - extent/2):int(centre + extent/2),\n",
    "                        int(centre - extent/2):int(centre + extent/2)]\n",
    "    # n.b. images are one the mirror of the other, hence the [:, ::-1]\n",
    "    shifts = rim.find_camera_registration_offset(image_0_b,\n",
    "                            image_1_b[:, ::-1])\n",
    "    shift_row += shifts[0] / len(slices_for_offset_calculation)\n",
    "    shift_col += shifts[1] / len(slices_for_offset_calculation)\n",
    "\n",
    "shift = np.asarray((shift_row, shift_col)).astype(np.int_)\n",
    "shifted_image= matut.shift_image(image_1[:,::-1], shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f6951",
   "metadata": {},
   "source": [
    "If you want to see the result of the offset calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_recap = plt.figure('offset recap', figsize=(15, 7))\n",
    "offset_recap.add_subplot(121)\n",
    "plt.imshow(image_0, alpha=.7, cmap='Oranges')\n",
    "plt.imshow(image_1[:, ::-1], alpha=.5, cmap='Blues')\n",
    "offset_recap.add_subplot(122)\n",
    "plt.imshow(image_0, alpha=.7, cmap='Oranges')\n",
    "plt.imshow(shifted_image, alpha=.5, cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nAverage shift: {shift} ([row, cols] in pixels)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf7b81",
   "metadata": {},
   "source": [
    "#### Temporal (rigid) registration\n",
    "\n",
    "Usually the sample suffers from a slow drift: it tends sinks.\n",
    "In order to find the drift vector, an analysis similar to the previous\n",
    "one is performed: a 3D cross-correlation between multiple couples\n",
    "of volumes. \n",
    "\n",
    "Any volume can be selected (CAM_00 or CAM_01),\n",
    "it will not impact the result. \n",
    "CAM_00 is selected by default.\n",
    "\n",
    "The first is always the starting volume, the second is\n",
    "as a function of time: it can be subtracted to each volume\n",
    "\n",
    "In the next sequence:\n",
    "\n",
    "1. Select the step [a.u., \"timesteps\"] used to include volumes\n",
    "   in the algorithm.\n",
    "\n",
    "2. A pictorial result can tell if it worked.\n",
    "    It should consist of 3 linear fits for the 3 displacement compontents.\n",
    "    Only one component is expected to be substantially != 0.\n",
    "    If it does not work: use smaller timestep.\n",
    "    If it still does not work: check the volumes \"by eye\", there must be something strange going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be43ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 20 # analysis performed every \"timestep\" volumes\n",
    "extent_x_y = 800 # use only a central region of \"extent_x_y\" pixels\n",
    "centre = IMAGES_DIMENSION / 2\n",
    "shifts_row, shifts_col, shifts_plane = [], [], []\n",
    "\n",
    "# by default we use camera 0, but using camera 1 is also fine.\n",
    "# (just change filename and Background accordingly)\n",
    "start_stack = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[0][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "\n",
    "for t in range(0, TIMEPOINTS, timestep):\n",
    "    \n",
    "    moving_stack = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[t][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "    \n",
    "    # Use only a central region (in the x-y plane)\n",
    "    moving_focus = moving_stack[\n",
    "    :,\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2),\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2)\n",
    "    ]\n",
    "    shift = rim.find_sample_drift(start_focus, moving_focus)\n",
    "    # Save the shift vector\n",
    "    shifts_plane.append(shift[0])\n",
    "    shifts_row.append(shift[1])\n",
    "    shifts_col.append(shift[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceabff4",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = p x\n",
    "def fit_simple(x, p):\n",
    "    return p * x\n",
    "# forcing the first point to be 0\n",
    "shifts_plane[0] = 0\n",
    "shifts_row[0] = 0\n",
    "shifts_col[0] = 0\n",
    "\n",
    "# STRONG LINEARITY ASSUMPTION\n",
    "# the starting slope used during the fit is simply\n",
    "# \"(final_y - starting_y) / (initial_x - starting_x)\"\n",
    "strong_linear_plane = shifts_plane[-1] / len(shifts_plane)\n",
    "strong_linear_row = shifts_row[-1] / len(shifts_plane)\n",
    "strong_linear_col = shifts_col[-1] / len(shifts_plane)\n",
    "\n",
    "x_plane = np.arange(0, len(shifts_plane), 1)\n",
    "x_row = np.arange(0, len(shifts_row), 1)\n",
    "x_col = np.arange(0, len(shifts_col), 1)\n",
    "\n",
    "fit_plane_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_plane,\n",
    "    shifts_plane,\n",
    "    p0=strong_linear_plane\n",
    "    )\n",
    "fit_row_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_row,\n",
    "    shifts_row,\n",
    "    p0=strong_linear_row\n",
    "    )\n",
    "fit_col_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_col,\n",
    "    shifts_col,\n",
    "    p0=strong_linear_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19161f12",
   "metadata": {},
   "source": [
    "#### Plots\n",
    "\n",
    "To summarize the temporal drift.\n",
    "Errorbars cover:\n",
    "- +/- 1 z-step for the depth\n",
    "- +/- 1 pixel for x/y drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = plt.figure('Temporal Drift Recap')\n",
    "\n",
    "summary.add_subplot(311)\n",
    "plt.title('Depth drift')\n",
    "plt.errorbar(x_plane, shifts_plane, yerr=1, fmt='o', color='dodgerblue')\n",
    "y_plane_0 = fit_plane_0[0] * x_plane\n",
    "plt.plot(x_plane, y_plane_0, '-', color='blue', alpha=.6)\n",
    "\n",
    "summary.add_subplot(312)\n",
    "plt.title('Vertical drift')\n",
    "plt.errorbar(x_row, shifts_row, yerr=1, fmt='o', color='orange')\n",
    "y_row_0 = fit_row_0[0] * x_row\n",
    "plt.plot(x_row, y_row_0, '-', color='red', alpha=.6)\n",
    "\n",
    "summary.add_subplot(313)\n",
    "plt.title('Horizontal drift')\n",
    "plt.errorbar(x_col, shifts_col, yerr=1, fmt='o', color='lightgreen')\n",
    "y_col_0 = fit_col_0[0] * x_col\n",
    "plt.plot(x_col, y_col_0, '-', color='green', alpha=.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# And print out the effective values that will be used \n",
    "# for the volumes processing\n",
    "print(f'\\nDepth drift: y = {fit_plane_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_plane}\\n')\n",
    "print(f'Vertical drift: y = {fit_row_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_row}\\n')\n",
    "print(f'Horizontal drift: y = {fit_col_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_col}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31197ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4850fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74aaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e1cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840bf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cf7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78343f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d2c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255757fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
