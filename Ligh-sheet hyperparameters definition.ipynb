{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ec832d",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d8c8e",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e5f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from scipy.optimize import curve_fit\n",
    "# local folder with homemade libraries\n",
    "sys.path.append('/home/ngc/Documents/GitHub/multiview_utilities')\n",
    "# HOMEMADE LIBRARIES AND IMPORTS\n",
    "import math_utils as matut\n",
    "import raw_images_manipulation_utilities as rim\n",
    "importlib.reload(matut);\n",
    "importlib.reload(rim); # reload the modules for updating to eventual changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aaec85",
   "metadata": {},
   "source": [
    "#### Local variables and constants.\n",
    "\n",
    "Carefully read and change the variables in the next sectionto match the volume to be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d58c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICES = 69 # number of images for each volume\n",
    "TIMEPOINTS =  200 # number of acquired volumes\n",
    "TOTAL_IMAGES = TIMEPOINTS * SLICES # total of raw data-images\n",
    "IMAGES_DIMENSION = 1024 # assumed square images.\n",
    "# N.b. try to have 2^n pixels: it speeds up FFt calculations.\n",
    "# Folder to get data and save data:\n",
    "RAW_SLICES_FOLDER = '/home/ngc/Desktop/test_data/561_2um'\n",
    "BACKGROUND_FOLDER = '/home/ngc/Desktop/test_data/561_2um'\n",
    "VOLUMES_OUTPUT_FOLDER = '/home/ngc/Desktop/test_data/outputs'\n",
    "PARAMS_OUTPUT_FOLDER = '/home/ngc/Desktop/test_data/params'\n",
    "\n",
    "# good compromise to most situations, in case we want to skip the slow section \"Feature extraction\"\n",
    "sigma = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbdb7df",
   "metadata": {},
   "source": [
    "Create a list of names of all the volumes as \n",
    "**[timepoint (int), vol_cam_0 [str], vol_cam_1 (str)]**\n",
    "next function uses a default file names paradigm, \n",
    "as saved by Labview software\n",
    "(check arguments in \"raw_images_manipulation_utilities\" library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf08b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = rim.file_names_list(TIMEPOINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f41f8b",
   "metadata": {},
   "source": [
    "#### Camera offset compensation\n",
    "\n",
    "The cameras are not pixel-exactly aligned: the offset in their views\n",
    "can be calculated with a 2D cross-correlation.\n",
    "This process returns a 2D displacement vector, \n",
    "that will be addedd (during image processing) to CAM_01 \n",
    "to have a better superpositoin with CAM_00.\n",
    "(the opposite is also fine, subtracting from CAM_00)\n",
    "In the next cell:\n",
    "\n",
    "1. Select a volume, and in that volume a (few) slice(s) that will be used to find the 2D mismatch.\n",
    "\n",
    "2. A pictorial result will tell if it worked. It should consist of: two superimposed imaged before displacement, after displacement, and a print() of the displacement vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0803333",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint_for_offset_calculation = 0 # it should not have any impact\n",
    "\n",
    "# select some slices to be used in the offset calculation.\\\n",
    "# Usually some central slices with a nice amount of information will do.\n",
    "slices_for_offset_calculation = np.asarray((10, 30, 40, 60)) \n",
    "# Instead of using all the image (it can be absolutely done) \n",
    "# go quicker and use only a square central region of \"extent\" side\n",
    "extent = 800\n",
    "\n",
    "centre = IMAGES_DIMENSION / 2\n",
    "shift_row, shift_col = 0, 0\n",
    "\n",
    "# Open the stacks\n",
    "stack_0 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint_for_offset_calculation][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "stack_1 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint_for_offset_calculation][2],\n",
    "    BACKGROUND_FOLDER + '/Background_1.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "\n",
    "for i in slices_for_offset_calculation:\n",
    "    image_0 = stack_0[i, :, :]\n",
    "    image_1 = stack_1[i, :, :]\n",
    "    image_0_b = image_0[int(centre - extent/2):int(centre + extent/2),\n",
    "                        int(centre - extent/2):int(centre + extent/2)]\n",
    "    image_1_b = image_1[int(centre - extent/2):int(centre + extent/2),\n",
    "                        int(centre - extent/2):int(centre + extent/2)]\n",
    "    # n.b. images are one the mirror of the other, hence the [:, ::-1]\n",
    "    shifts = rim.find_camera_registration_offset(image_0_b,\n",
    "                            image_1_b[:, ::-1])\n",
    "    shift_row += shifts[0] / len(slices_for_offset_calculation)\n",
    "    shift_col += shifts[1] / len(slices_for_offset_calculation)\n",
    "\n",
    "shift = np.asarray((shift_row, shift_col)).astype(np.int_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd2037",
   "metadata": {},
   "source": [
    "If you want to see the result of the offset calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a15bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shift: [ 1 , 16 ], ([row, cols] in pixels)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# choose any 2 slices\n",
    "image_0 = stack_0[60, :, :]\n",
    "image_1 = stack_1[60, :, :]\n",
    "shifted_image = matut.shift_image(image_1[:,::-1], shift)\n",
    "\n",
    "offset_recap = plt.figure('offset recap', figsize=(15, 7))\n",
    "offset_recap.add_subplot(121)\n",
    "plt.title('Before')\n",
    "plt.imshow(image_0, alpha=.7, cmap='Oranges')\n",
    "plt.imshow(image_1[:, ::-1], alpha=.5, cmap='Blues')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Pixels')\n",
    "offset_recap.add_subplot(122)\n",
    "plt.title('After')\n",
    "plt.imshow(image_0, alpha=.7, cmap='Oranges')\n",
    "plt.imshow(shifted_image, alpha=.5, cmap='Blues')\n",
    "plt.xlabel('Pixels')\n",
    "plt.show()\n",
    "print(f'\\nComputed shift: [', shift[0], ',', shift[1], '], ([row, cols] in pixels)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6b40a",
   "metadata": {},
   "source": [
    "#### Temporal (rigid) registration\n",
    "\n",
    "Usually the sample suffers from a slow drift: it tends sinks.\n",
    "In order to find the drift vector, an analysis similar to the previous\n",
    "one is performed: a 3D cross-correlation between multiple couples\n",
    "of volumes. \n",
    "\n",
    "Any volume can be selected (CAM_00 or CAM_01),\n",
    "it will not impact the result. \n",
    "CAM_00 is selected by default.\n",
    "\n",
    "The first is always the starting volume, the second is\n",
    "as a function of time: it can be subtracted to each volume\n",
    "\n",
    "In the next sequence:\n",
    "\n",
    "1. Select the step [a.u., \"timesteps\"] used to include volumes\n",
    "   in the algorithm.\n",
    "\n",
    "2. A pictorial result can tell if it worked.\n",
    "    It should consist of 3 linear fits for the 3 displacement compontents.\n",
    "    Only one component is expected to be substantially != 0.\n",
    "    If it does not work: use smaller timestep.\n",
    "    If it still does not work: check the volumes \"by eye\", there must be something strange going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f8d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 50 # analysis performed every \"timestep\" volumes\n",
    "extent_x_y = 800 # use only a central region of \"extent_x_y\" pixels\n",
    "centre = IMAGES_DIMENSION / 2\n",
    "shifts_row, shifts_col, shifts_plane = [], [], []\n",
    "\n",
    "# by default we use camera 0, but using camera 1 is also fine.\n",
    "# (just change filename and Background accordingly)\n",
    "start_stack = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[0][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "\n",
    "start_focus = start_stack[\n",
    "    :,\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2),\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2)\n",
    "    ]\n",
    "\n",
    "for t in range(0, TIMEPOINTS, timestep):\n",
    "    \n",
    "    moving_stack = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[t][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "    \n",
    "    # Use only a central region (in the x-y plane)\n",
    "    moving_focus = moving_stack[\n",
    "    :,\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2),\n",
    "    int(centre - extent_x_y/2):int(centre + extent_x_y/2)\n",
    "    ]\n",
    "    shift = rim.find_sample_drift(start_focus, moving_focus)\n",
    "    # Save the shift vector\n",
    "    shifts_plane.append(shift[0])\n",
    "    shifts_row.append(shift[1])\n",
    "    shifts_col.append(shift[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af74d60",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307d1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = p x\n",
    "def fit_simple(x, p):\n",
    "    return p * x\n",
    "# forcing the first point to be 0\n",
    "shifts_plane[0] = 0\n",
    "shifts_row[0] = 0\n",
    "shifts_col[0] = 0\n",
    "\n",
    "# STRONG LINEARITY ASSUMPTION\n",
    "# the starting slope used during the fit is simply\n",
    "# \"(final_y - starting_y) / (initial_x - starting_x)\"\n",
    "strong_linear_plane = shifts_plane[-1] / len(shifts_plane)\n",
    "strong_linear_row = shifts_row[-1] / len(shifts_plane)\n",
    "strong_linear_col = shifts_col[-1] / len(shifts_plane)\n",
    "\n",
    "x_plane = np.arange(0, len(shifts_plane), 1)\n",
    "x_row = np.arange(0, len(shifts_row), 1)\n",
    "x_col = np.arange(0, len(shifts_col), 1)\n",
    "\n",
    "fit_plane_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_plane,\n",
    "    shifts_plane,\n",
    "    p0=strong_linear_plane\n",
    "    )\n",
    "fit_row_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_row,\n",
    "    shifts_row,\n",
    "    p0=strong_linear_row\n",
    "    )\n",
    "fit_col_0 = curve_fit(\n",
    "    fit_simple,\n",
    "    x_col,\n",
    "    shifts_col,\n",
    "    p0=strong_linear_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672cb5b",
   "metadata": {},
   "source": [
    "#### Plots\n",
    "\n",
    "To summarize the temporal drift.\n",
    "Errorbars cover:\n",
    "- +/- 1 z-step for the depth\n",
    "- +/- 1 pixel for x/y drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180c7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depth drift: y = [0.21428571] * x\n",
      "With only first and last points would give: 0.125\n",
      "\n",
      "Vertical drift: y = [-1.64285714] * x\n",
      "With only first and last points would give: -1.25\n",
      "\n",
      "Horizontal drift: y = [-1.78571429] * x\n",
      "With only first and last points would give: -1.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = plt.figure('Temporal Drift Recap')\n",
    "\n",
    "summary.add_subplot(311)\n",
    "plt.title('Depth drift')\n",
    "plt.errorbar(x_plane, shifts_plane, yerr=1, fmt='o', color='dodgerblue')\n",
    "y_plane_0 = fit_plane_0[0] * x_plane\n",
    "plt.plot(x_plane, y_plane_0, '-', color='blue', alpha=.6)\n",
    "\n",
    "summary.add_subplot(312)\n",
    "plt.title('Vertical drift')\n",
    "plt.errorbar(x_row, shifts_row, yerr=1, fmt='o', color='orange')\n",
    "y_row_0 = fit_row_0[0] * x_row\n",
    "plt.plot(x_row, y_row_0, '-', color='red', alpha=.6)\n",
    "\n",
    "summary.add_subplot(313)\n",
    "plt.title('Horizontal drift')\n",
    "plt.errorbar(x_col, shifts_col, yerr=1, fmt='o', color='lightgreen')\n",
    "y_col_0 = fit_col_0[0] * x_col\n",
    "plt.plot(x_col, y_col_0, '-', color='green', alpha=.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# And print out the effective values that will be used \n",
    "# for the volumes processing\n",
    "print(f'\\nDepth drift: y = {fit_plane_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_plane}\\n')\n",
    "print(f'Vertical drift: y = {fit_row_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_row}\\n')\n",
    "print(f'Horizontal drift: y = {fit_col_0[0]} * x')   \n",
    "print(f'With only first and last points would give: {strong_linear_col}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6963e",
   "metadata": {},
   "source": [
    " ### Feature extraction\n",
    "To merge images following Preibish et al. approximation to local entropy,\n",
    "two sigmas must be selected. The first one should be larger than the linear\n",
    "dimension of sensible features.\n",
    "e.g. feature = 10 pixels, value = 15 pixels (???)\n",
    "Find it with the cursos over the image,\n",
    "and then save it in \"sigma\" value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e78cca",
   "metadata": {},
   "source": [
    "This may take a longer time then the rest.\n",
    "It is in general a non essential part.\n",
    "\n",
    "When merging, each view must contribute to the final image proportianally to the local amount of information it contains.\n",
    "To measure this *local amount of information* various methods can be used. All give similar results.\n",
    "Here a method from Preibish et al. is used.([article](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/6914/1/Mosaicing-of-single-plane-illumination-microscopy-images-using-groupwise-registration/10.1117/12.770893.full?SSO=1))\n",
    "The local information is approximated by the local standar deviation of each pixel. The definition of \"local\" is somehow arbitrary. For every pixel we look at a nerghborhood of 20 pixels. In general the local region extent can be tuned to maximaze the difference between the two images. The rationale is the following: when the two images are considered as bringing the same amount of information, a simple average is performed. If one image is much more informative than the other (in a particular region) then it should be condered **much more** than the other.\n",
    "\n",
    "In practice, the local standard deviation is approximated by taking the difference between the original image and a low-pass filtered verion of itself: the extent of the gaussian employed in the filtering operatin determines the extent of what is considered *local*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5c66e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a volume\n",
    "timepoint = 0\n",
    "\n",
    "# Open the stacks\n",
    "stack_0 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint][1],\n",
    "    BACKGROUND_FOLDER + '/Background_0.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "stack_1 = rim.open_binary_stack(\n",
    "    RAW_SLICES_FOLDER + data_list[timepoint][2],\n",
    "    BACKGROUND_FOLDER + '/Background_1.tif',\n",
    "    size_x=IMAGES_DIMENSION,\n",
    "    size_y=IMAGES_DIMENSION)\n",
    "\n",
    "diff = []\n",
    "# maximum extent of the local region\n",
    "exploration_range = 70\n",
    "\n",
    "# Choose an image for offset calculation\n",
    "selected_slice = 40\n",
    "\n",
    "for i in range(2, exploration_range):\n",
    "    # define the low-pass filtering gaussian\n",
    "    Gaus_1 = matut.gaussian_2D(stack_0.shape[1], [0,0], i+1)\n",
    "    Gaus_1 = matut.FT2(Gaus_1)\n",
    "    # local information evaluation\n",
    "    w_1 = np.abs(stack_0[selected_slice, :, :] \\\n",
    "        - matut.IFT2((matut.FT2(stack_0[selected_slice, :, :]) * Gaus_1)))**2\n",
    "    w_2 = np.abs(stack_1[selected_slice, :, :] \\\n",
    "        - matut.IFT2((matut.FT2(stack_0[selected_slice, :, ::-1]) * Gaus_1)))**2\n",
    "    # evaluate the difference between normalized local weights\n",
    "    diff.append(np.sum(np.abs(w_1/np.amax(w_1+w_2) - w_2/np.amax(w_2+w_1))))\n",
    "\n",
    "sigma = np.argmax(diff) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e0b08",
   "metadata": {},
   "source": [
    "#### Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bad4b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.figure('Find the sigma: local information comparison')\n",
    "plt.plot(np.arange(len(diff)), diff/np.amax(diff), '.--')\n",
    "plt.xlabel('Local extend (side of square ROI) [pixels]')\n",
    "plt.ylabel('Local information difference [a.u.]')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa0e0b",
   "metadata": {},
   "source": [
    "Saving all the hyperparameters in a .csv\n",
    "- cameras offset\n",
    "- drift fit parameters\n",
    "- sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73a8a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    PARAMS_OUTPUT_FOLDER + '/hyperparameters.csv',\n",
    "    'w',#\n",
    "    newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow([\"Parameter\", \"Value\"])\n",
    "    writer.writerow([\"Camera vertical offset\", 1])\n",
    "    writer.writerow([\"Camera horizontal offset\", 1])\n",
    "    writer.writerow([\"T drift - depth\", np.round(fit_plane_0[0][0], 2)])\n",
    "    writer.writerow([\"T drift - vertical\", np.round(fit_row_0[0][0], 2)])\n",
    "    writer.writerow([\"T drift - horizontal\", np.round(fit_col_0[0][0], 2)])\n",
    "    writer.writerow([\"sigma\", np.round(sigma, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc974769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
